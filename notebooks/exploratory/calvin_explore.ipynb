{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import Sequential\n",
    "# from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, MaxPool2D\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.path.join(os.pardir, os.pardir, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal train images: 1341\n",
      "Pneumonia train images: 3876\n",
      "Test normal images: 234\n",
      "Test pneumonia images: 390\n"
     ]
    }
   ],
   "source": [
    "train_ = os.path.join(data,'train')\n",
    "test_ = os.path.join(data, 'test')\n",
    "\n",
    "norm_train = os.path.join(train_, 'NORMAL')\n",
    "print('Normal train images:', len(os.listdir(norm_train)))\n",
    "pa_train = os.path.join(train_, 'PNEUMONIA')\n",
    "print('Pneumonia train images:', len(os.listdir(pa_train)))\n",
    "\n",
    "norm_test = os.path.join(test_, 'NORMAL')\n",
    "print('Test normal images:', len(os.listdir(norm_test)))\n",
    "pa_test = os.path.join(test_, 'PNEUMONIA')\n",
    "print('Test pneumonia images:', len(os.listdir(pa_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Generators & Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5217 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 256\n",
    "batch_size = 8\n",
    "\n",
    "train_data_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "val_data_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_data_gen.flow_from_directory(train_, target_size=(image_size, image_size),\n",
    "                                               batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "val_gen = val_data_gen.flow_from_directory(test_, target_size=(image_size, image_size),\n",
    "                                           batch_size=batch_size, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                        input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0414 14:33:19.222735 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0414 14:33:19.456033 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 326 steps, validate for 39 steps\n",
      "Epoch 1/5\n",
      "326/326 [==============================] - 73s 224ms/step - loss: 0.2210 - accuracy: 0.9242 - val_loss: 0.5642 - val_accuracy: 0.7853\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.0767 - accuracy: 0.9729 - val_loss: 0.6346 - val_accuracy: 0.7772\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 72s 219ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.8945 - val_accuracy: 0.7676\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 71s 218ms/step - loss: 0.0347 - accuracy: 0.9904 - val_loss: 0.9470 - val_accuracy: 0.7708\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 71s 218ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 1.0303 - val_accuracy: 0.7644\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                        input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0414 14:39:18.018510 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0414 14:39:18.208963 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 326 steps, validate for 39 steps\n",
      "Epoch 1/5\n",
      "326/326 [==============================] - 82s 250ms/step - loss: 0.2059 - accuracy: 0.9212 - val_loss: 1.6801 - val_accuracy: 0.6587\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 80s 246ms/step - loss: 0.0993 - accuracy: 0.9658 - val_loss: 1.0489 - val_accuracy: 0.7452\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 80s 246ms/step - loss: 0.0743 - accuracy: 0.9729 - val_loss: 0.9342 - val_accuracy: 0.7596\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 80s 245ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 1.2251 - val_accuracy: 0.7452\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 80s 246ms/step - loss: 0.0455 - accuracy: 0.9840 - val_loss: 0.9697 - val_accuracy: 0.7933\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model2.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                        input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0414 15:44:49.631290 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0414 15:44:49.842042 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 326 steps, validate for 39 steps\n",
      "Epoch 1/5\n",
      "326/326 [==============================] - 92s 284ms/step - loss: 0.0422 - accuracy: 0.9846 - val_loss: 1.1586 - val_accuracy: 0.7580\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 88s 271ms/step - loss: 0.0325 - accuracy: 0.9883 - val_loss: 1.9892 - val_accuracy: 0.7244\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 89s 272ms/step - loss: 0.0464 - accuracy: 0.9813 - val_loss: 1.7357 - val_accuracy: 0.7244\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 89s 273ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 1.2842 - val_accuracy: 0.7356\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 89s 272ms/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 2.4535 - val_accuracy: 0.7196\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model2.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.add(Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                        input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "model4.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0414 16:11:34.101411 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0414 16:11:34.313944 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 326 steps, validate for 39 steps\n",
      "Epoch 1/5\n",
      "326/326 [==============================] - 88s 271ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 2.5065 - val_accuracy: 0.7324\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 89s 273ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 1.7822 - val_accuracy: 0.7196\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 85s 261ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 2.5897 - val_accuracy: 0.7340\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 87s 265ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1732 - val_accuracy: 0.7147\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 88s 270ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 3.7066 - val_accuracy: 0.6955\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model2.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.add(Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                        input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model5.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model5.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model5.add(Flatten())\n",
    "\n",
    "model5.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0414 16:20:41.495738 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0414 16:20:41.718341 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 326 steps, validate for 39 steps\n",
      "Epoch 1/5\n",
      "326/326 [==============================] - 87s 267ms/step - loss: 0.0448 - accuracy: 0.9842 - val_loss: 2.4713 - val_accuracy: 0.7292\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 88s 269ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 4.9182 - val_accuracy: 0.6971\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 87s 268ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 3.5973 - val_accuracy: 0.7324\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 88s 269ms/step - loss: 7.0436e-04 - accuracy: 1.0000 - val_loss: 3.3565 - val_accuracy: 0.7452\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 88s 269ms/step - loss: 3.7896e-04 - accuracy: 1.0000 - val_loss: 4.4154 - val_accuracy: 0.7099\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model2.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.add(Conv2D(64, kernel_size=(3, 3), activation='relu',\n",
    "                        input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0414 16:42:57.774345 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0414 16:42:57.978294 4388752832 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 326 steps, validate for 39 steps\n",
      "Epoch 1/5\n",
      "326/326 [==============================] - 93s 286ms/step - loss: 0.2339 - accuracy: 0.9198 - val_loss: 0.5362 - val_accuracy: 0.7965\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 88s 269ms/step - loss: 0.0702 - accuracy: 0.9746 - val_loss: 0.9853 - val_accuracy: 0.7292\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 87s 268ms/step - loss: 0.0434 - accuracy: 0.9862 - val_loss: 1.1900 - val_accuracy: 0.7260\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 87s 267ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 2.4533 - val_accuracy: 0.6747\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 87s 268ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 1.0933 - val_accuracy: 0.7548\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model6.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.add(Conv2D(64, kernel_size=(3, 3), activation='relu',\n",
    "                        input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0414 20:05:41.402510 4432158144 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0414 20:05:41.593049 4432158144 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 326 steps, validate for 39 steps\n",
      "Epoch 1/5\n",
      "326/326 [==============================] - 93s 284ms/step - loss: 0.4738 - accuracy: 0.8852 - val_loss: 0.4124 - val_accuracy: 0.8397\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 93s 284ms/step - loss: 0.1282 - accuracy: 0.9544 - val_loss: 0.9616 - val_accuracy: 0.7692\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 93s 285ms/step - loss: 0.1040 - accuracy: 0.9671 - val_loss: 2.0835 - val_accuracy: 0.7115\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 514s 2s/step - loss: 0.0739 - accuracy: 0.9764 - val_loss: 1.4161 - val_accuracy: 0.7660\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 89s 273ms/step - loss: 0.0715 - accuracy: 0.9804 - val_loss: 2.0449 - val_accuracy: 0.7179\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model6.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(image_size, image_size, 3)))\n",
    "model7.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model7.add(SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model7.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model7.add(SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model7.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model7.add(SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model7.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model7.add(Dropout(rate=0.3))\n",
    "\n",
    "model7.add(SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model7.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(units=64, activation='relu'))\n",
    "model7.add(Dropout(rate=0.3))\n",
    "\n",
    "model7.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0414 21:08:14.926841 4432158144 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0414 21:08:15.096027 4432158144 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 326 steps, validate for 39 steps\n",
      "Epoch 1/5\n",
      "326/326 [==============================] - 108s 330ms/step - loss: 0.5803 - accuracy: 0.7406 - val_loss: 0.6689 - val_accuracy: 0.6250\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 106s 325ms/step - loss: 0.4444 - accuracy: 0.7875 - val_loss: 0.7520 - val_accuracy: 0.7019\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 108s 331ms/step - loss: 0.2816 - accuracy: 0.8700 - val_loss: 0.4530 - val_accuracy: 0.8061\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 107s 329ms/step - loss: 0.2349 - accuracy: 0.8991 - val_loss: 0.7228 - val_accuracy: 0.7179\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 107s 329ms/step - loss: 0.1784 - accuracy: 0.9285 - val_loss: 1.2971 - val_accuracy: 0.7051\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model7.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(image_size, image_size, 3)))\n",
    "model8.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(rate=0.3))\n",
    "\n",
    "model8.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model8.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(rate=0.4))\n",
    "\n",
    "model8.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model8.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(rate=0.5))\n",
    "\n",
    "model8.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model8.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(rate=0.4))\n",
    "\n",
    "model8.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model8.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(rate=0.3))\n",
    "\n",
    "model8.add(Flatten())\n",
    "\n",
    "model8.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0415 12:01:30.272451 4511653312 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0415 12:01:30.339076 4511653312 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 652 steps, validate for 78 steps\n",
      "Epoch 1/5\n",
      "652/652 [==============================] - 621s 953ms/step - loss: 0.4132 - accuracy: 0.8361 - val_loss: 0.3948 - val_accuracy: 0.8109\n",
      "Epoch 2/5\n",
      "652/652 [==============================] - 603s 925ms/step - loss: 0.2026 - accuracy: 0.9311 - val_loss: 0.8238 - val_accuracy: 0.7276\n",
      "Epoch 3/5\n",
      "652/652 [==============================] - 570s 874ms/step - loss: 0.1753 - accuracy: 0.9441 - val_loss: 0.4569 - val_accuracy: 0.8253\n",
      "Epoch 4/5\n",
      "652/652 [==============================] - 570s 874ms/step - loss: 0.1563 - accuracy: 0.9532 - val_loss: 0.7002 - val_accuracy: 0.7837\n",
      "Epoch 5/5\n",
      "652/652 [==============================] - 568s 870ms/step - loss: 0.1503 - accuracy: 0.9557 - val_loss: 0.7633 - val_accuracy: 0.7612\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model8.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(image_size, image_size, 3)))\n",
    "model9.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(rate=0.4))\n",
    "\n",
    "model9.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model9.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(rate=0.4))\n",
    "\n",
    "model9.add(Flatten())\n",
    "model9.add(Dense(units=128, activation='relu'))\n",
    "model9.add(Dropout(rate=0.4))\n",
    "\n",
    "model9.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0415 17:26:15.585274 4511653312 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0415 17:26:15.652457 4511653312 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 652 steps, validate for 78 steps\n",
      "Epoch 1/5\n",
      "652/652 [==============================] - 1037s 2s/step - loss: 1.3610 - accuracy: 0.8424 - val_loss: 0.6744 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "652/652 [==============================] - 1096s 2s/step - loss: 0.2823 - accuracy: 0.9236 - val_loss: 0.5394 - val_accuracy: 0.8718\n",
      "Epoch 3/5\n",
      "652/652 [==============================] - 1003s 2s/step - loss: 0.2507 - accuracy: 0.9432 - val_loss: 0.7251 - val_accuracy: 0.7740\n",
      "Epoch 4/5\n",
      "652/652 [==============================] - 950s 1s/step - loss: 0.1958 - accuracy: 0.9482 - val_loss: 1.0876 - val_accuracy: 0.7580\n",
      "Epoch 5/5\n",
      "652/652 [==============================] - 975s 1s/step - loss: 0.1873 - accuracy: 0.9535 - val_loss: 0.7208 - val_accuracy: 0.7468\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "model9.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "           validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(image_size, image_size, 3)))\n",
    "model10.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(rate=0.4))\n",
    "\n",
    "model10.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model10.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(rate=0.4))\n",
    "\n",
    "model10.add(Flatten())\n",
    "model10.add(Dense(units=128, activation='relu'))\n",
    "model10.add(Dropout(rate=0.4))\n",
    "\n",
    "model10.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0416 08:56:59.435674 4511653312 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0416 08:56:59.501179 4511653312 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 652 steps, validate for 78 steps\n",
      "Epoch 1/5\n",
      "652/652 [==============================] - 1382s 2s/step - loss: 0.2666 - accuracy: 0.9418 - val_loss: 0.8914 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "652/652 [==============================] - 1409s 2s/step - loss: 0.2066 - accuracy: 0.9518 - val_loss: 0.9022 - val_accuracy: 0.7276\n",
      "Epoch 3/5\n",
      "652/652 [==============================] - 1467s 2s/step - loss: 0.1887 - accuracy: 0.9533 - val_loss: 1.4098 - val_accuracy: 0.7420\n",
      "Epoch 4/5\n",
      "652/652 [==============================] - 1435s 2s/step - loss: 0.1692 - accuracy: 0.9578 - val_loss: 0.7460 - val_accuracy: 0.7837\n",
      "Epoch 5/5\n",
      "652/652 [==============================] - 1397s 2s/step - loss: 0.1686 - accuracy: 0.9566 - val_loss: 0.5942 - val_accuracy: 0.7724\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_gen.n // batch_size\n",
    "validation_steps = val_gen.n // batch_size\n",
    "\n",
    "history = model10.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_gen, epochs=5,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup test model to be visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (768, 8) Y shape: (768, 1)\n",
      "Epoch 1/10\n",
      "768/768 [==============================] - 0s 243us/step - loss: 1.0308 - accuracy: 0.6510\n",
      "Epoch 2/10\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.6942 - accuracy: 0.6510\n",
      "Epoch 3/10\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6688 - accuracy: 0.6497\n",
      "Epoch 4/10\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.6669 - accuracy: 0.6497\n",
      "Epoch 5/10\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.6580 - accuracy: 0.6497\n",
      "Epoch 6/10\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6513 - accuracy: 0.6510\n",
      "Epoch 7/10\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.6509 - accuracy: 0.6497\n",
      "Epoch 8/10\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.6467 - accuracy: 0.6510\n",
      "Epoch 9/10\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6438 - accuracy: 0.6510\n",
      "Epoch 10/10\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.6373 - accuracy: 0.6510\n",
      "768/768 [==============================] - 0s 39us/step\n",
      "\n",
      "accuracy: 64.97%\n"
     ]
    }
   ],
   "source": [
    "# The following is adapted from: \n",
    "# https://towardsdatascience.com/visualizing-artificial-neural-networks-anns-with-just-one-line-of-code-b4233607209e\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "# load pima indians dataset\n",
    "db_data = os.path.join(data,'diabetes.csv')\n",
    "dataset = pd.read_csv(db_data)\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset.drop(['Outcome'],axis =1)\n",
    "Y = pd.DataFrame(dataset['Outcome'])\n",
    "\n",
    "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)\n",
    "\n",
    "# # create model\n",
    "model11 = Sequential()\n",
    "model11.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model11.add(Dense(8, activation='relu'))\n",
    "model11.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model11.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model11.fit(X, Y, epochs=10, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model11.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model11.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install ann_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ann_visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and use ann_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "ann_viz(model11, title=\"Neural Network Sample Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_viz(model9, title=\"Neural Network Model 9 Visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
